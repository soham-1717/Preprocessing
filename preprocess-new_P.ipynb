{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\soham\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\soham\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\soham\\anaconda3\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\soham\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\soham\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Define Variables & Helper Functions\n",
    "\n",
    "Define variables that are needed thoughout the data preparation pipeline. These include environment specific information like locations for images, training & test data and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.abspath('..')\n",
    "\n",
    "# Path for the COCO label files\n",
    "COCO_LABELS_PATH = os.path.join(PROJECT_DIR, 'labels', 'coco')\n",
    "\n",
    "# Path for working data (ignored by git)\n",
    "DATA_PATH = os.path.join(PROJECT_DIR, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_coco(merged_coco, subset_coco):\n",
    "    category_id_map = {}\n",
    "    next_category_id = len(merged_coco[\"categories\"]) + 1\n",
    "    image_id_offset = len(merged_coco[\"images\"])\n",
    "    annotation_id_offset = len(merged_coco[\"annotations\"])\n",
    "\n",
    "    for category in merged_coco[\"categories\"]:\n",
    "        category_id_map[category[\"name\"]] = category[\"id\"]\n",
    "\n",
    "    for category in subset_coco[\"categories\"]:\n",
    "        if category[\"name\"] not in category_id_map.keys():\n",
    "            category_id_map[category[\"name\"]] = next_category_id\n",
    "            next_category_id += 1\n",
    "\n",
    "    for image in subset_coco[\"images\"]:\n",
    "        image[\"id\"] += image_id_offset\n",
    "        merged_coco[\"images\"].append(image)\n",
    "\n",
    "    for annotation in subset_coco[\"annotations\"]:\n",
    "        annotation[\"id\"] += annotation_id_offset\n",
    "        annotation[\"image_id\"] += image_id_offset\n",
    "        annotation[\"category_id\"] = category_id_map[\n",
    "            subset_coco[\"categories\"][annotation[\"category_id\"] - 1][\"name\"]\n",
    "        ]\n",
    "        merged_coco[\"annotations\"].append(annotation)\n",
    "\n",
    "    merged_coco[\"categories\"] = [\n",
    "        {\"id\": id, \"name\": name, \"supercategory\": \"\"}\n",
    "        for name, id in category_id_map.items()\n",
    "    ]\n",
    "\n",
    "    return merged_coco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Extract Data\n",
    "\n",
    "Unpack the zipped raw images provided to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file C:\\Users\\Soham\\Downloads\\labels_coco-20240612T222844Z-001.zip exists.\n",
      "Extracted all files to C:\\Users\\Soham\\Downloads\\extracted_labels\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Define the direct path to the zip file\n",
    "zip_file_path = r\"C:\\Users\\Soham\\Downloads\\labels_coco-20240612T222844Z-001.zip\"\n",
    "\n",
    "# Define the directory to extract to\n",
    "extract_path = r\"C:\\Users\\Soham\\Downloads\\extracted_labels\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(zip_file_path):\n",
    "    print(f\"The file {zip_file_path} exists.\")\n",
    "    \n",
    "    # Try extracting the zip file\n",
    "    try:\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(extract_path, exist_ok=True)\n",
    "        \n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        print(f\"Extracted all files to {extract_path}\")\n",
    "    except PermissionError as e:\n",
    "        print(f\"PermissionError: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "else:\n",
    "    print(f\"The file {zip_file_path} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Merge Labels\n",
    "\n",
    "Process the subsets of labels provided in CoCo labelling format to merge the labelling done by the different students. The process combines the categories (i.e. labels), images and annotations of the different CoCo files so that we have one set of categories/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: C:\\Users\\Soham\\Downloads\\extracted_labels\\labels_coco\\coco-merged.json\\instances_default.json\n",
      "Processing labels_01 with 395 images and 601 annotations\n",
      "Processing labels_02 with 395 images and 346 annotations\n",
      "Processing labels_03 with 395 images and 346 annotations\n",
      "Processing labels_04 with 395 images and 494 annotations\n",
      "Processing labels_05 with 396 images and 633 annotations\n",
      "Processing labels_06 with 395 images and 386 annotations\n",
      "Processing labels_07 with 395 images and 423 annotations\n",
      "Processing labels_08 with 395 images and 435 annotations\n",
      "Processing labels_09 with 395 images and 398 annotations\n",
      "Processing labels_10 with 396 images and 467 annotations\n",
      "Total images: 3952, Total annotations: 4529\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define your paths\n",
    "COCO_LABELS_PATH = r'C:\\Users\\Soham\\Downloads\\extracted_labels\\labels_coco'\n",
    "DATA_PATH = r'C:\\Users\\Soham\\Downloads'\n",
    "\n",
    "# Initialize coco_merged dictionary\n",
    "coco_merged = { 'categories': [], 'images': [], 'annotations': [] }\n",
    "\n",
    "image_count = 0\n",
    "annotation_count = 0\n",
    "\n",
    "# Ensure COCO_LABELS_PATH exists and iterate over its folders\n",
    "if os.path.exists(COCO_LABELS_PATH):\n",
    "    for subset_folder in os.listdir(COCO_LABELS_PATH):\n",
    "        label_file_path = os.path.join(COCO_LABELS_PATH, subset_folder, 'instances_default.json')\n",
    "\n",
    "        # Check if the JSON file exists\n",
    "        if os.path.exists(label_file_path):\n",
    "            with open(label_file_path) as f:\n",
    "                coco_json = json.load(f)\n",
    "                image_count += len(coco_json['images'])\n",
    "                annotation_count += len(coco_json['annotations'])\n",
    "                print(f\"Processing {subset_folder} with {len(coco_json['images'])} images and {len(coco_json['annotations'])} annotations\")\n",
    "                # Merge the current coco_json into coco_merged\n",
    "                coco_merged = merge_coco(coco_merged, coco_json)\n",
    "        else:\n",
    "            print(f\"File not found: {label_file_path}\")\n",
    "\n",
    "    # Dump coco_merged to a JSON file\n",
    "    with open(os.path.join(DATA_PATH, 'coco-merged.json'), 'w') as outfile:\n",
    "        json.dump(coco_merged, outfile)\n",
    "        \n",
    "    print(f\"Total images: {image_count}, Total annotations: {annotation_count}\")\n",
    "else:\n",
    "    print(f\"Directory not found: {COCO_LABELS_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: C:\\Users\\Soham\\Downloads\\extracted_labels\\labels_coco\\coco-merged.json\\instances_default.json\n",
      "Processing labels_01 with 395 images and 601 annotations\n",
      "Processing labels_02 with 395 images and 346 annotations\n",
      "Processing labels_03 with 395 images and 346 annotations\n",
      "Processing labels_04 with 395 images and 494 annotations\n",
      "Processing labels_05 with 396 images and 633 annotations\n",
      "Processing labels_06 with 395 images and 386 annotations\n",
      "Processing labels_07 with 395 images and 423 annotations\n",
      "Processing labels_08 with 395 images and 435 annotations\n",
      "Processing labels_09 with 395 images and 398 annotations\n",
      "Processing labels_10 with 396 images and 467 annotations\n",
      "Total images: 3952, Total annotations: 4529\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define your paths\n",
    "COCO_LABELS_PATH = r'C:\\Users\\Soham\\Downloads\\extracted_labels\\labels_coco'\n",
    "DATA_PATH = r'C:\\Users\\Soham\\Downloads'\n",
    "\n",
    "# Initialize coco_merged dictionary\n",
    "coco_merged = { 'categories': [], 'images': [], 'annotations': [] }\n",
    "\n",
    "image_count = 0\n",
    "annotation_count = 0\n",
    "\n",
    "# Ensure COCO_LABELS_PATH exists and iterate over its folders\n",
    "if os.path.exists(COCO_LABELS_PATH):\n",
    "    for subset_folder in os.listdir(COCO_LABELS_PATH):\n",
    "        label_file_path = os.path.join(COCO_LABELS_PATH, subset_folder, 'instances_default.json')\n",
    "\n",
    "        # Check if the JSON file exists\n",
    "        if os.path.exists(label_file_path):\n",
    "            with open(label_file_path) as f:\n",
    "                coco_json = json.load(f)\n",
    "                image_count += len(coco_json['images'])\n",
    "                annotation_count += len(coco_json['annotations'])\n",
    "                print(f\"Processing {subset_folder} with {len(coco_json['images'])} images and {len(coco_json['annotations'])} annotations\")\n",
    "                # Merge the current coco_json into coco_merged\n",
    "                coco_merged = merge_coco(coco_merged, coco_json)\n",
    "        else:\n",
    "            print(f\"File not found: {label_file_path}\")\n",
    "\n",
    "    # Dump coco_merged to a JSON file after the loop completes\n",
    "    with open(os.path.join(DATA_PATH, 'coco-merged.json'), 'w') as outfile:\n",
    "        json.dump(coco_merged, outfile)\n",
    "        \n",
    "    print(f\"Total images: {image_count}, Total annotations: {annotation_count}\")\n",
    "else:\n",
    "    print(f\"Directory not found: {COCO_LABELS_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 3952 images but got 3612\n",
      "Expected 4 annotations but got 4428\n",
      "ID: 1: construction_work\n",
      "ID: 2: defective_sign_post\n",
      "ID: 3: drilling_ret_wall\n",
      "ID: 4: sagging\n",
      "ID: 8: deposit\n",
      "ID: 9: pipeline\n",
      "ID: 10: drilling\n"
     ]
    }
   ],
   "source": [
    "# Run some validation checks & print info\n",
    "if len(coco_merged['images']) != image_count:\n",
    "    print(f\"Expected {image_count} images but got {len(coco_merged['images'])}\")\n",
    "else:\n",
    "    print(f\"{image_count} images in merged file\")\n",
    "if len(coco_merged['annotations']) != annotation_count:\n",
    "    print(f\"Expected {annotation_count} annotations but got {len(coco_merged['annotations'])}\")\n",
    "else:\n",
    "    print(f\"{annotation_count} annotations in merged file\")\n",
    "\n",
    "for category in coco_merged['categories']:\n",
    "    print(f\"ID: {category['id']}: {category['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: construction_work (ID: 1) - Annotations: 3050\n",
      "Category: defective_sign_post (ID: 2) - Annotations: 320\n",
      "Category: drilling_ret_wall (ID: 3) - Annotations: 52\n",
      "Category: sagging (ID: 4) - Annotations: 307\n",
      "Category: deposit (ID: 8) - Annotations: 489\n",
      "Category: pipeline (ID: 9) - Annotations: 206\n",
      "Category: drilling (ID: 10) - Annotations: 4\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store category-wise annotation counts\n",
    "category_annotation_counts = {category['id']: 0 for category in coco_merged['categories']}\n",
    "\n",
    "# Count annotations by category\n",
    "for annotation in coco_merged['annotations']:\n",
    "    category_id = annotation['category_id']\n",
    "    if category_id in category_annotation_counts:\n",
    "        category_annotation_counts[category_id] += 1\n",
    "    else:\n",
    "        category_annotation_counts[category_id] = 1\n",
    "\n",
    "# Print category-wise annotation counts\n",
    "for category in coco_merged['categories']:\n",
    "    category_id = category['id']\n",
    "    category_name = category['name']\n",
    "    annotation_count = category_annotation_counts[category_id]\n",
    "    print(f\"Category: {category_name} (ID: {category_id}) - Annotations: {annotation_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Filter Categories, Annotations, Images\n",
    "\n",
    "Filter categories, annotations and images based on the removal of certain labels/classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 3 categories\n",
      "Filtered 117 annotations\n",
      "Filtered 366 images\n",
      "Filtered data saved to C:\\Users\\Soham\\Downloads\\extracted_labels\\labels_coco\\labels\\coco\\instances_default.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "DATA_PATH = r'C:\\Users\\Soham\\Downloads\\extracted_labels\\labels_coco'\n",
    "FILTER_IDS = [5, 6, 7]\n",
    "\n",
    "# Load coco_merged from file if not already loaded\n",
    "coco_merged_path = os.path.join(DATA_PATH, 'coco-merged.json')\n",
    "if os.path.exists(coco_merged_path):\n",
    "    with open(coco_merged_path, 'r') as f:\n",
    "        coco_merged = json.load(f)\n",
    "else:\n",
    "    raise FileNotFoundError(f'{coco_merged_path} not found. Please make sure to run the previous merging script.')\n",
    "\n",
    "# Count categories and annotations before filtering\n",
    "pre_filter_cat_count = len(coco_merged[\"categories\"])\n",
    "pre_filter_ann_count = len(coco_merged[\"annotations\"])\n",
    "\n",
    "# Filter categories and annotations based on FILTER_IDS\n",
    "coco_merged[\"categories\"] = [\n",
    "    category\n",
    "    for category in coco_merged[\"categories\"]\n",
    "    if category[\"id\"] not in FILTER_IDS\n",
    "]\n",
    "coco_merged[\"annotations\"] = [\n",
    "    annotation\n",
    "    for annotation in coco_merged[\"annotations\"]\n",
    "    if annotation[\"category_id\"] not in FILTER_IDS\n",
    "]\n",
    "\n",
    "# Count categories and annotations after filtering\n",
    "post_filter_cat_count = len(coco_merged[\"categories\"])\n",
    "post_filter_ann_count = len(coco_merged[\"annotations\"])\n",
    "\n",
    "print(f\"Filtered {pre_filter_cat_count - post_filter_cat_count} categories\")\n",
    "print(f\"Filtered {pre_filter_ann_count - post_filter_ann_count} annotations\")\n",
    "\n",
    "# Filter images that don't have annotations\n",
    "pre_filter_img_count = len(coco_merged[\"images\"])\n",
    "\n",
    "# Create a set of image IDs that have annotations\n",
    "annotated_image_ids = set(annotation[\"image_id\"] for annotation in coco_merged[\"annotations\"])\n",
    "\n",
    "# Filter images\n",
    "coco_merged[\"images\"] = [\n",
    "    image\n",
    "    for image in coco_merged[\"images\"]\n",
    "    if image[\"id\"] in annotated_image_ids\n",
    "]\n",
    "\n",
    "# Count images after filtering\n",
    "post_filter_img_count = len(coco_merged[\"images\"])\n",
    "print(f\"Filtered {pre_filter_img_count - post_filter_img_count} images\")\n",
    "\n",
    "# Save the filtered file\n",
    "filtered_labels_path = os.path.join(DATA_PATH, \"labels\", \"coco\")\n",
    "os.makedirs(filtered_labels_path, exist_ok=True)\n",
    "\n",
    "filtered_json_path = os.path.join(filtered_labels_path, \"instances_default.json\")\n",
    "with open(filtered_json_path, \"w\") as f:\n",
    "    json.dump(coco_merged, f)\n",
    "\n",
    "print(f\"Filtered data saved to {filtered_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3982 images in merged file\n",
      "5016 annotations in merged file\n"
     ]
    }
   ],
   "source": [
    "if coco_merged is None:\n",
    "    coco_merged = json.load(open(os.path.join(DATA_PATH, 'coco-merged.json')))\n",
    "\n",
    "print(f\"{len(coco_merged['images'])} images in merged file\")\n",
    "print(f\"{len(coco_merged['annotations'])} annotations in merged file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create Train/Test Split\n",
    "\n",
    "Create a ~~stratified~~ (currently not stratified) train/test split and store the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3185 images, Test: 797 images\n"
     ]
    }
   ],
   "source": [
    "# TBD: do a proper startified split\n",
    "images = np.array([image[\"file_name\"] for image in coco_merged['images']])\n",
    "train, test = train_test_split(images, test_size=0.2, random_state=42)\n",
    "json.dump({ \"train\": train.tolist(), \"test\": test.tolist() }, open(os.path.join(DATA_PATH, 'train_test_split.json'), 'w'))\n",
    "print(f\"Train: {len(train)} images, Test: {len(test)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
